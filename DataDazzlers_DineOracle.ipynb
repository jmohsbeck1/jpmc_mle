{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmohsbeck1/jpmc_mle/blob/final_project/DataDazzlers_DineOracle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkcL3oVnbZM"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lniIH38EnW6L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import itertools\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-zPQ4FAFznJ"
      },
      "outputs": [],
      "source": [
        "#Dataframe and numerical library\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "#Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "\n",
        "#Machine Learming Model\n",
        "#Metrics\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Model Selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Linear Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "#Ensemble\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "#Others\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Hyper parameter\n",
        "from sklearn import neighbors, datasets, model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Import"
      ],
      "metadata": {
        "id": "9Em1NTnhQjy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: Import large dataset using opendatasets\n",
        "if not os.path.exists('yelp-dataset'):\n",
        "  print(\"Loading Keys\")\n",
        "  kaggle_key = 'ravikiranbutti'\n",
        "  kaggle_value = '117268fa41345f39e5baeda66733a0c7'\n",
        "  os.environ['KAGGLE_USERNAME'] = kaggle_key\n",
        "  os.environ['KAGGLE_KEY'] = kaggle_value\n",
        "  !mkdir -p /root/.kaggle\n",
        "  with open('/root/.kaggle/kaggle.json', 'w') as kaggle_file:\n",
        "    kaggle_file.write('{\"username\":\"' + kaggle_key + '\",\"key\":\"' + kaggle_value + '\"}')\n",
        "\n",
        "  print(\"Loading Data\")\n",
        "  !pip install kaggle\n",
        "  !kaggle datasets download yelp-dataset/yelp-dataset\n",
        "  !unzip yelp-dataset.zip -d 'yelp-dataset'\n",
        "  !rm yelp-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWsH-ih3FvcR",
        "outputId": "c12d17d3-3e7e-4162-f9e4-70d5198c2bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Keys\n",
            "Loading Keys\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Downloading yelp-dataset.zip to /content\n",
            "100% 4.07G/4.07G [03:00<00:00, 24.4MB/s]\n",
            "100% 4.07G/4.07G [03:00<00:00, 24.3MB/s]\n",
            "Archive:  yelp-dataset.zip\n",
            "  inflating: yelp-dataset/Dataset_User_Agreement.pdf  \n",
            "  inflating: yelp-dataset/yelp_academic_dataset_business.json  \n",
            "  inflating: yelp-dataset/yelp_academic_dataset_checkin.json  \n",
            "  inflating: yelp-dataset/yelp_academic_dataset_review.json  \n",
            "  inflating: yelp-dataset/yelp_academic_dataset_tip.json  \n",
            "  inflating: yelp-dataset/yelp_academic_dataset_user.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: Load Business using chunk processing\n",
        "business_chunks = pd.read_json(\"yelp-dataset/yelp_academic_dataset_business.json\", lines=True, chunksize=10000)\n",
        "business = pd.concat(business_chunks) "
      ],
      "metadata": {
        "id": "Eugk1tT70-b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print information\n",
        "business.info()"
      ],
      "metadata": {
        "id": "C-jnI5o91GLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4810eced-e031-4e44-c8ea-fd0c44265f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150346 entries, 0 to 150345\n",
            "Data columns (total 14 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   business_id   150346 non-null  object \n",
            " 1   name          150346 non-null  object \n",
            " 2   address       150346 non-null  object \n",
            " 3   city          150346 non-null  object \n",
            " 4   state         150346 non-null  object \n",
            " 5   postal_code   150346 non-null  object \n",
            " 6   latitude      150346 non-null  float64\n",
            " 7   longitude     150346 non-null  float64\n",
            " 8   stars         150346 non-null  float64\n",
            " 9   review_count  150346 non-null  int64  \n",
            " 10  is_open       150346 non-null  int64  \n",
            " 11  attributes    136602 non-null  object \n",
            " 12  categories    150243 non-null  object \n",
            " 13  hours         127123 non-null  object \n",
            "dtypes: float64(3), int64(2), object(9)\n",
            "memory usage: 16.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: Load Review using chunk processing and filtering unwanted colums\n",
        "review = []\n",
        "review_dtypes = {\"stars\": np.float16, \n",
        "            \"useful\": np.int32, \n",
        "            \"funny\": np.int32,\n",
        "            \"cool\": np.int32,\n",
        "           }\n",
        "with open(\"yelp-dataset/yelp_academic_dataset_review.json\", \"r\") as f:\n",
        "    review_chunks = pd.read_json(f, orient=\"records\", lines=True, dtype=review_dtypes, chunksize=1000)\n",
        "        \n",
        "    for review_chunk in review_chunks:\n",
        "        reduced_review_chunk = review_chunk.drop(columns=['review_id', 'useful','funny','cool', 'text','date'])\n",
        "        review.append(reduced_review_chunk)\n",
        "    \n",
        "review = pd.concat(review, ignore_index=True)"
      ],
      "metadata": {
        "id": "mEZA1vZ_1BFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print information\n",
        "review.info()"
      ],
      "metadata": {
        "id": "BamYSoE_1G7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd4f640-76ef-47e6-a5b0-f5d67036acb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6990280 entries, 0 to 6990279\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Dtype  \n",
            "---  ------       -----  \n",
            " 0   user_id      object \n",
            " 1   business_id  object \n",
            " 2   stars        float16\n",
            "dtypes: float16(1), object(2)\n",
            "memory usage: 120.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: Load User using chunk processing and filtering unwanted colums\n",
        "user = []\n",
        "with open(\"yelp-dataset/yelp_academic_dataset_user.json\", \"r\") as f:\n",
        "    user_chunks = pd.read_json(f, orient=\"records\", lines=True, chunksize=1000)\n",
        "        \n",
        "    for user_chunk in user_chunks:\n",
        "        reduced_user_chunk = user_chunk.drop(columns=['name', 'useful','funny','cool', 'elite','friends'])\n",
        "        user.append(reduced_user_chunk)\n",
        "    \n",
        "user = pd.concat(user, ignore_index=True)"
      ],
      "metadata": {
        "id": "QS_UbyE01C3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print information\n",
        "user.info()"
      ],
      "metadata": {
        "id": "hKqA0z-41IPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a321b77-6484-4edc-876f-cd9d2794009f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1987897 entries, 0 to 1987896\n",
            "Data columns (total 16 columns):\n",
            " #   Column              Dtype  \n",
            "---  ------              -----  \n",
            " 0   user_id             object \n",
            " 1   review_count        int64  \n",
            " 2   yelping_since       object \n",
            " 3   fans                int64  \n",
            " 4   average_stars       float64\n",
            " 5   compliment_hot      int64  \n",
            " 6   compliment_more     int64  \n",
            " 7   compliment_profile  int64  \n",
            " 8   compliment_cute     int64  \n",
            " 9   compliment_list     int64  \n",
            " 10  compliment_note     int64  \n",
            " 11  compliment_plain    int64  \n",
            " 12  compliment_cool     int64  \n",
            " 13  compliment_funny    int64  \n",
            " 14  compliment_writer   int64  \n",
            " 15  compliment_photos   int64  \n",
            "dtypes: float64(1), int64(13), object(2)\n",
            "memory usage: 242.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleanup"
      ],
      "metadata": {
        "id": "FxtBnkd-QplS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXPv-V7cQvus"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}