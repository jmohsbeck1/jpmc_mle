{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmohsbeck1/jpmc_mle/blob/week-Apr.-17/Data_Dazzalers_Grid_Search_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PevmXENNeaeV"
      },
      "outputs": [],
      "source": [
        "#Dataframe and numerical library\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "#Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "\n",
        "#Machine Learming Model\n",
        "#Metrics\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Model Selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Linear Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "#Ensemble\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "#Others\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Hyper parameter\n",
        "from sklearn import neighbors, datasets, model_selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"data.csv\")\n",
        "# df.sample(5)"
      ],
      "metadata": {
        "id": "I7PRg7OlfbIk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How to Tune Batch Size and Number of Epochs"
      ],
      "metadata": {
        "id": "c5DSdz1KOCuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFF7vOPShfKz",
        "outputId": "e099bedb-7448-43c2-f7c3-cc17da238ae7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-45026021416b>:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.714844 using {'batch_size': 10, 'epochs': 100}\n",
            "0.584635 (0.050865) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.652344 (0.003189) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.714844 (0.014616) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.625000 (0.011500) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.658854 (0.021710) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.687500 (0.011500) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.588542 (0.047019) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.630208 (0.036966) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.679688 (0.008438) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.574219 (0.033299) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.652344 (0.022326) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.658854 (0.027866) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.558594 (0.055335) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.625000 (0.006379) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.638021 (0.043303) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.419271 (0.051560) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.596354 (0.032578) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.647135 (0.017566) with: {'batch_size': 100, 'epochs': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How to Tune the Training Optimization Algorithm"
      ],
      "metadata": {
        "id": "JbdNMQAOO9lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "dEnHuUankvFc",
        "outputId": "c777173f-054d-4a0f-e937-0a89cf4021be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9c1e32bac31e>:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.703125 using {'optimizer': 'Adam'}\n",
            "0.653646 (0.012075) with: {'optimizer': 'SGD'}\n",
            "0.680990 (0.055823) with: {'optimizer': 'RMSprop'}\n",
            "0.476562 (0.075409) with: {'optimizer': 'Adagrad'}\n",
            "0.591146 (0.070192) with: {'optimizer': 'Adadelta'}\n",
            "0.703125 (0.019401) with: {'optimizer': 'Adam'}\n",
            "0.645833 (0.060375) with: {'optimizer': 'Adamax'}\n",
            "0.690104 (0.023510) with: {'optimizer': 'Nadam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How to Tune Learning Rate and Momentum"
      ],
      "metadata": {
        "id": "E_Ge_wR6QXdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the learning rate and momentum\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZTDD3mwQOGE",
        "outputId": "f1575998-06c7-454c-b5da-908594945d62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1177429a2c62>:27: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.670573 using {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.670573 (0.043537) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.660156 (0.030758) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "0.657552 (0.014382) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
            "0.648438 (0.028348) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
            "0.648438 (0.028348) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
            "0.619792 (0.049032) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.648438 (0.030758) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "0.647135 (0.027126) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
            "0.656250 (0.024080) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "0.664062 (0.020915) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
            "0.647135 (0.030145) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
            "0.649740 (0.026557) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
            "0.658854 (0.032578) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "0.657552 (0.034401) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
            "0.649740 (0.026557) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
            "0.649740 (0.026557) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
            "0.651042 (0.027126) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
            "0.660156 (0.000000) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
            "0.654948 (0.004872) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
            "0.660156 (0.033754) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
            "0.649740 (0.026557) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
            "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How to Tune Network Weight Initialization"
      ],
      "metadata": {
        "id": "FtgBY0mBRbd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the weight initialization\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(init_mode='uniform'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3i8cAn9Ro96",
        "outputId": "dfde50c7-2d3c-433b-afb7-4a5394bd8ccd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b09f0e916be8>:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.723958 using {'init_mode': 'uniform'}\n",
            "0.723958 (0.028587) with: {'init_mode': 'uniform'}\n",
            "0.718750 (0.024080) with: {'init_mode': 'lecun_uniform'}\n",
            "0.699219 (0.019401) with: {'init_mode': 'normal'}\n",
            "0.651042 (0.024774) with: {'init_mode': 'zero'}\n",
            "0.654948 (0.029463) with: {'init_mode': 'glorot_normal'}\n",
            "0.695312 (0.013902) with: {'init_mode': 'glorot_uniform'}\n",
            "0.710938 (0.042910) with: {'init_mode': 'he_normal'}\n",
            "0.694010 (0.006639) with: {'init_mode': 'he_uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How to Tune the Neuron Activation Function"
      ],
      "metadata": {
        "id": "RDGZv34WTjMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the activation function\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation='relu'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation=activation))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXy4fs_3TpKE",
        "outputId": "b6411160-df2c-4934-ab01-b00e4e835dc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3fd56db634af>:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.743490 using {'activation': 'softplus'}\n",
            "0.635417 (0.018136) with: {'activation': 'softmax'}\n",
            "0.743490 (0.027126) with: {'activation': 'softplus'}\n",
            "0.674479 (0.017566) with: {'activation': 'softsign'}\n",
            "0.721354 (0.010253) with: {'activation': 'relu'}\n",
            "0.674479 (0.019225) with: {'activation': 'tanh'}\n",
            "0.701823 (0.004872) with: {'activation': 'sigmoid'}\n",
            "0.678385 (0.027866) with: {'activation': 'hard_sigmoid'}\n",
            "0.712240 (0.001841) with: {'activation': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How to Tune Dropout Regularization"
      ],
      "metadata": {
        "id": "rj_Lc9dsVltM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the dropout rate\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.constraints import maxnorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(weight_constraint)))\n",
        "\tmodel.add(Dropout(dropout_rate))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "weight_constraint = [1, 2, 3, 4, 5]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "5FaQCFIoWUdg",
        "outputId": "ad086885-1b62-4b5f-ac4f-fb6ae54d329b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f085b4fd4b84>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaxnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Function to create model, required for KerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'maxnorm' from 'tensorflow.keras.constraints' (/usr/local/lib/python3.9/dist-packages/keras/api/_v2/keras/constraints/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}